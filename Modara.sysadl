Model SysADLModel ; package SysADL.types { value type Int { } value type Boolean { } value type String { } value type Void { } value type Real { } } package modara_components { import SysADL.types ; import modara_connectors ; import modara_ports ; boundary
	component def ConsumptionModuleCP { ports : dOpt5 : DataOPT ; dIpt5 : DataIPT ; } boundary
	component def ServingModuleCP { ports :   dIpt3 : DataIPT ; dOpt3 : DataOPT ; } boundary
	component def StorageModuleCP { ports : dOpt6 : DataOPT ; dIpt6 : DataIPT ; configuration { components : DataLakeCP : DataLakeCP ; DataWarehouseCP : DataWarehouseCP ; NoSQLDatabaseCP : NoSQLDatabaseCP ; } }
	component def StreamProcessingModuleCP { ports : so : StreamDataOPT ; si : StreamDataIPT ; oi2 : OrchestratorIPT ; }
	component def BatchProcessingModuleCP { ports : bo : BatchDataOPT ; bi : BatchDataIPT ; oi : OrchestratorIPT ; } boundary
	component def GovernanceModuleCP { configuration { components : DataPrivacyCP : DataPrivacyCP ; LifeCycleRulesCP : AuditModuleCP ; MetadataManagementCP : MetadataManagementCP ; } } boundary
	component def IntegrationModuleCP { ports : dIpt10 : DataIPT ; dOpt10_2 : StreamDataOPT ; dOpt10_1 : BatchDataOPT ; } boundary
	component def DataProvisionModuleCP { ports : dOpt9 : DataOPT ; dIpt9 : DataIPT ; }
	component def AnalyticalModuleCP { ports : dIpt2 : DataIPT ; dOpt2 : DataOPT ; }
	component def BigDataApplicationProviderCP { ports : bdIpt1 : DataIPT ; bdOpt2 : DataOPT ; bdIpt2 : DataIPT ; bdOpt1 : DataOPT ; configuration { components : integration : IntegrationModuleCP { using ports : dIpt10 : DataIPT ;  dOpt10_2 : StreamDataOPT ; dOpt10_1 : BatchDataOPT ;} serving : ServingModuleCP { using ports : dOpt3 : DataOPT ; dIpt3 : DataIPT ; } batch : BatchProcessingModuleCP { using ports : baOpt : BatchDataOPT ; baIpt : BatchDataIPT ; } stream : StreamProcessingModuleCP { using ports : strOpt : StreamDataOPT ; strIPT : StreamDataIPT ; }  analytical : AnalyticalModuleCP { using ports : dIpt2 : DataIPT ; dOpt2 : DataOPT ; } quality : DataQualityModuleCP { using ports : dIpt1 : DataIPT ; dOpt1 : DataOPT ; } connectors : is : StreamDataFlowCN bindings dOpt10_2 = strIPT ; bs : BatchDataFlowCN bindings dOpt2 = dIpt3 ; n2 : BatchDataFlowCN bindings baOpt = dIpt2 ; n1 : BatchDataFlowCN bindings strOpt = dIpt1 ; n3 : BatchDataFlowCN bindings dOpt1 = dIpt2 ; delegations : dIpt10 to bdIpt1 dOpt3 to bdOpt2 dOpt10_1 to bdOpt1 baIpt to bdIpt2 } }
	component def BigDataFrameworkProviderCP { configuration { components : GovernanceModuleCP : GovernanceModuleCP ; StorageModuleCP : StorageModuleCP ; } } architecture def MoDaRA { ports : configuration { components :     SystemOrchestratorCP : SystemOrchestratorCP ; BigDataApplicationProviderCP : BigDataApplicationProviderCP { using ports : bdIpt2 : DataIPT ; bdOpt1 : DataOPT ; bdIpt1 : DataIPT ; } provider : DataProviderCP { using ports : dIpt8 : DataIPT ; dOpt8 : DataOPT ; } consumer : DataConsumerCP { using ports : dIpt4 : DataIPT ; dOpt4 : DataOPT ; } BigDataFrameworkProviderCP : BigDataFrameworkProviderCP ; } }
	component def SystemOrchestratorCP { ports : oo : OrchestratorOPT ; configuration { } } component def DataProviderCP { ports : dIpt8 : DataIPT ; dOpt8 : DataOPT ; configuration { components : DataProvisionModuleCP : DataProvisionModuleCP { using ports : dOpt9 : DataOPT ; dIpt9 : DataIPT ; } delegations : dOpt9 to dOpt8 dIpt9 to dIpt8 } }
	component def DataConsumerCP { ports : dIpt4 : DataIPT ; dOpt4 : DataOPT ; mIpt3 : MetadataIPT ; configuration { components : ConsumptionModuleCP : ConsumptionModuleCP { using ports : dOpt5 : DataOPT ; dIpt5 : DataIPT ; } delegations : dIpt5 to dIpt4 dOpt5 to dOpt4 } }
	component def DataQualityModuleCP { ports :    dIpt1 : DataIPT ; dOpt1 : DataOPT ; }
	component def AuditModuleCP { ports : mIpt3 : MetadataIPT ; mOpt3 : MetadataOPT ; }
	component def MetadataManagementCP { ports : mIpt1 : MetadataIPT ; mOpt1 : MetadataOPT ; }
	component def DataPrivacyCP { ports : mIpt2 : MetadataIPT ; mOpt2 : MetadataOPT ; }
	component def DataLakeCP { ports : dIpt12 : DataIPT ; dOpt12 : DataOPT ; }
	component def DataWarehouseCP { ports : mOpt2 : MetadataOPT ; dOpt7 : DataOPT ; dIpt7 : DataIPT ; } component def NoSQLDatabaseCP { ports : dIpt13 : DataIPT ; dOpt13 : DataOPT ; } } package modara_connectors { import modara_ports ;            connector def DataFlowCN { participants : ~ dOpt : DataOPT ; ~ dIpt : DataIPT ; flows : Data from dOpt to dIpt } connector def BatchDataFlowCN { participants : ~ bdOpt : BatchDataOPT ; ~ bdIpt : BatchDataIPT ; flows : BatchData from bdOpt to bdIpt } connector def OrchestratorFlowCN { participants : ~ ofOpt : OrchestratorOPT ; ~ ofIpt : OrchestratorIPT ; flows : Data from ofOpt to ofIpt } connector def StreamDataFlowCN { participants : ~ sdOpt : StreamDataOPT ; ~ sdIpt : StreamDataIPT ; flows : StreamData from sdOpt to sdIpt } connector def MetadataFlowCN { participants : ~ mdOpt : MetadataOPT ; ~ mdIpt : MetadataIPT ; flows : Metadata from mdOpt to mdIpt } } package modara_ports { import modara_types ;    port def StreamDataIPT { flow in StreamData } port def StreamDataOPT { flow out StreamData } port def BatchDataIPT { flow in BatchData } port def BatchDataOPT { flow out BatchData }                port def OrchestratorOPT { flow out Data } port def OrchestratorIPT { flow in Data } port def MetadataIPT { flow in Metadata } port def MetadataOPT { flow out Metadata } port def DataIPT { flow in Data } port def DataOPT { flow out Data } } package modara_types { import SysADL.types ; value type StreamData extends Data { dimension = DataFormat } value type Data { dimension = DataFormat } value type BatchData extends Data { dimension = DataFormat }   unit Parquet { } unit Json { } unit CSV { } dimension DataFormat value type Metadata extends Data { dimension = DataFormat } } package concrete_architecture { import modara_components ; import modara_ports ;
	component def ConcreteArchitecture { ports : dataOpt : DataOPT ; dataIpt : DataIPT ; configuration { components :             ApplicationDatabase : DataProviderCP { using ports : dIpt8 : DataIPT ; dOpt8 : DataOPT ; } Stitch : IntegrationModuleCP { using ports : dIpt10 : DataIPT ; dOpt10_2 : StreamDataOPT ; dOpt10_1 : BatchDataOPT ; } RawLayer : DataLakeCP { using ports : dIpt12 : DataIPT ; dOpt12 : DataOPT ; } Databricks_BronzeLayer : DataWarehouseCP { using ports : mOpt1 : MetadataOPT ; dOpt7_3 : DataOPT ; dIpt7_3 : DataIPT ; } Databricks_SilverLayer : DataWarehouseCP { using ports : mOpt2 : MetadataOPT ; dOpt7_2 : DataOPT ; dIpt7_2 : DataIPT ; } Databricks_GoldLayer : DataWarehouseCP { using ports : mOpt3 : MetadataOPT ; dOpt7_1 : DataOPT ; dIpt7_1 : DataIPT ; } BronzeTranf : BatchProcessingModuleCP { using ports : bo1 : BatchDataOPT ; bi1 : BatchDataIPT ; oi1 : OrchestratorIPT ; } SilverTransf : BatchProcessingModuleCP { using ports : bo2 : BatchDataOPT ; bi2 : BatchDataIPT ; oi2 : OrchestratorIPT ; } GoldTransf : BatchProcessingModuleCP { using ports : bo3 : BatchDataOPT ; bi3 : BatchDataIPT ; oi3 : OrchestratorIPT ; } HiveMetastore : MetadataManagementCP { using ports : mIpt1 : MetadataIPT ; mOpt5 : MetadataOPT ; } DatabricksWorkflows : SystemOrchestratorCP { using ports : oo : OrchestratorOPT ; } LookerDashboard : DataConsumerCP { using ports : dIpt4 : DataIPT ; dOpt4 : DataOPT ; mIpt3 : MetadataIPT ; } connectors :        o1 : OrchestratorFlowCN bindings oo = oi1 ; o2 : OrchestratorFlowCN bindings oo = oi2 ; o3 : OrchestratorFlowCN bindings oo = oi3 ; m1 : MetadataFlowCN bindings mOpt1 = mIpt1 ; m2 : MetadataFlowCN bindings mOpt2 = mIpt1 ; m3 : MetadataFlowCN bindings mOpt3 = mIpt1 ; m4 : MetadataFlowCN bindings mOpt5 = mIpt3 ; df1 : DataFlowCN bindings dOpt7_1 = dIpt4 ; df2 : DataFlowCN bindings dOpt8 = dIpt10 ; b1 : BatchDataFlowCN bindings dOpt10_1 = dIpt12 ; b2 : BatchDataFlowCN bindings dOpt12 = bi1 ; b3 : BatchDataFlowCN bindings bo1 = dIpt7_3 ; b4 : BatchDataFlowCN bindings dOpt7_3 = bi2 ; b5 : BatchDataFlowCN bindings bo2 = dIpt7_2 ; b6 : BatchDataFlowCN bindings dOpt7_2 = bi3 ; b7 : BatchDataFlowCN bindings bo3 = dIpt7_1 ; delegations : dIpt8 to dataIpt dOpt4 to dataOpt } } component def LinkedinArchitecture { ports : dataInput : DataIPT ; dataOutput : DataOPT ; configuration { components : ApacheKafka_Topic : IntegrationModuleCP { using ports : dIpt10 : DataIPT ; dOpt10_2 : StreamDataOPT ; dOpt10_1 : BatchDataOPT ; } OracleDatabase : DataProvisionModuleCP { using ports : dOpt9 : DataOPT ; dIpt9 : DataIPT ; } Azkaban : SystemOrchestratorCP { using ports : oo : OrchestratorOPT ; } ApacheKafka_Streaming : StreamProcessingModuleCP { using ports : so : StreamDataOPT ; si : StreamDataIPT ; oi2 : OrchestratorIPT ; } Hadoop_MapReduce_ETL : BatchProcessingModuleCP { using ports : bo : BatchDataOPT ; bi : BatchDataIPT ; oi : OrchestratorIPT ; } Hadoop_HDFS : StorageModuleCP { using ports : do3 : DataOPT ; di3 : DataIPT ; } Avatara : ConsumptionModuleCP { using ports : do5 : DataOPT ; dIpt5 : DataIPT ; } Voldermort_Staging : StorageModuleCP { using ports : do2 : DataOPT ; di2 : DataIPT ; } Voldemort_ReadOnly : StorageModuleCP { using ports : do4 : DataOPT ; di4 : DataIPT ; } connectors : s1 : StreamDataFlowCN bindings dOpt10_2 = si ; o1 : OrchestratorFlowCN bindings oo = oi2 ; o2 : OrchestratorFlowCN bindings oo = oi ; b1 : BatchDataFlowCN bindings dOpt9 = bi ; s2 : StreamDataFlowCN bindings so = di2 ; s3 : BatchDataFlowCN bindings bo = di3 ; b4 : BatchDataFlowCN bindings do3 = di4 ; d5 : DataFlowCN bindings do4 = dIpt5 ; delegations : dIpt10 to dataInput dIpt9 to dataInput do5 to dataOutput } }
	component def BigDataIndustry40Architecture { ports : dataInput : DataIPT ; dataOutput : DataOPT ; configuration { components : Database : DataProvisionModuleCP { using ports : do1 : DataOPT ; di1 : DataIPT ; } Talend : IntegrationModuleCP { using ports : di3 : DataIPT ; do3_1 : StreamDataOPT ; do3_2 : BatchDataOPT ; } ApacheKafka_Topic : IntegrationModuleCP { using ports : di4 : DataIPT ; do4_1 : StreamDataOPT ; do4_2 : BatchDataOPT ; } Hadoop_HDFS : DataLakeCP { using ports : di5 : DataIPT ; do5 : DataOPT ; } Hive : DataWarehouseCP { using ports : mOpt2 : MetadataOPT ; do6 : DataOPT ; di6 : DataIPT ; } PrestoSQL : ServingModuleCP { using ports : di7 : DataIPT ; do7 : DataOPT ; } WebService : DataConsumerCP { using ports : di8 : DataIPT ; do8 : DataOPT ; mIpt3 : MetadataIPT ; } WebServices : DataProvisionModuleCP { using ports : do2 : DataOPT ; di2 : DataIPT ; } connectors : c1 : BatchDataFlowCN bindings do1 = di3 ; c2 : DataFlowCN bindings do2 = di4 ; c5 : BatchDataFlowCN bindings do5 = di6 ; c6 : DataFlowCN bindings do6 = di7 ; c7 : DataFlowCN bindings do7 = di8 ; c3 : BatchDataFlowCN bindings do3_2 = di5 ; c4 : StreamDataFlowCN bindings do4_1 = di6 ; delegations : di1 to dataInput do8 to dataOutput di2 to dataInput } } }